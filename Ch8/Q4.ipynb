{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chapter 8, Q4 (a) Do Exercise 40.8 in MacKay’s book (MacKay 2003). It is cited here as follows: Estimate in bits the total sensory experience that you have had in your life – visual information, auditory information, etc. Estimate how much information you have memorized. Estimate the information content of the works of Shakespeare. Compare these with the capacity of your brain assuming you have 10<sup>11</sup> neurons each making 1000 synaptic connections and that the (information) capacity result for one neuron (two bits per connection) applies. Is your brain full yet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In order to estimate in bits the total sensory experience that you have had in my life, one would have to consider the amount of visual information perceived, auditory information heard, tactile sensations felt, etc. For now we will consider only Visual and Auditory information for the sake of simplicity. \n",
    "<li> Visual Information: The human eye can perceive a wide range of visual stimuli, including colors, shapes, textures, and movement. Estimates suggest that the human eye can distinguish around 10 million colors and perceive details down to about 0.1 degrees of visual angle. If we consider the resolution of the human eye, the amount of visual information perceived over a lifetime would be in the order of terabytes. <br> \n",
    "\n",
    "Let's assume an average human lifespan of 80 years, which is approximately 2.52 billion seconds. Now, the human visual system can perceive a wide range of visual stimuli, including colors, shapes, textures, and movement. \n",
    "\n",
    "Total Visual Information = Resolution of Human Eye * Duration of Lifetime\n",
    "\n",
    "Let's assume each pixel requires 3 bytes to represent color information (assuming 24-bit color depth, with 8 bits per channel for red, green, and blue). This is a common representation for standard RGB color. So, the calculation becomes:\n",
    "\n",
    "Total Visual Information in bytes = Resolution of Human Eye * Size per Pixel\n",
    "\n",
    "Given that the resolution of both eyes is estimated at 576 million pixels and each pixel requires 3 bytes, the calculation becomes:\n",
    "\n",
    "Total Visual Information in bytes ≈ 576 million pixels * 3 bytes/pixel\n",
    "\n",
    "Total Visual Information in bytes ≈ **1.728 billion bytes**\n",
    "\n",
    "\n",
    "<li> Auditory Information: The human ear can detect sounds across a broad range of frequencies and amplitudes. The dynamic range of human hearing is estimated to be around 120 decibels, and the auditory system can perceive subtle differences in pitch, timbre, and spatial location. Estimating the amount of auditory information processed would again be estimated in the order of terabytes. Let's make a rough estimation using a bitrate of 1 Mbps (which is conservative compared to high-quality audio formats): <br>\n",
    "\n",
    "Total Auditory Information = Duration of Lifetime * Bitrate\n",
    "= 2.52 billion seconds * 1 Mbps\n",
    "\n",
    "This would give us a total auditory information estimate of approximately 2.52 exabytes (1 exabyte = 10<sup>18</sup> bytes).\n",
    "\n",
    "To convert this to terabytes, we can divide by 1000 (since 1 exabyte = 1000 petabytes, and 1 petabyte = 1000 terabytes):\n",
    "\n",
    "Total Auditory Information in Terabytes ≈ 2.52 exabytes / 1000 ≈ **2.52 million terabytes**\n",
    "\n",
    "<li> Now, given capacity is: Number of Neurons: 10^11 neurons,\n",
    "Number of Synaptic Connections per Neuron: 1000,\n",
    "Information Capacity per Synaptic Connection: 2 bits (as assumed)\n",
    "\n",
    "So, Total information capacity of the brain = Number of neurons * Number of synaptic connections per neuron * Information capacity per synaptic connection\n",
    "\n",
    "= 10^11 neurons * 1000 connections/neuron * 2 bits/connection\n",
    "\n",
    "= 2 * 10^14 bits\n",
    "\n",
    "<li> Therefore, Total sensory experience ≈ 2.02 * 10^25 bits (for auditory)\n",
    "\n",
    "Total sensory experience ≈ 1.382 * 10^10 bits (for visual)\n",
    "\n",
    "Estimated Memorized Information ≈ 8 * 10^14 bits\n",
    "\n",
    "It's evident that the estimated sensory experience, both auditory and visual combined, far exceeds the theoretical capacity of the brain, while the estimated memorized information is much smaller in comparison. \n",
    "\n",
    "<li> However, this does not necessarily mean the brain is full. Because the brain responds to change in stimuli. For example, if it sees the same information, it recognizes the visual or audio from previously stored information, instead of storing it again. Even if the stimuli is new, we are often only able to retain specific details of it and not a high fidelity recall. <br>\n",
    "\n",
    "##### To estimate the information content of the works of Shakespeare, we need to consider the total number of words in his collected works and then convert this into bits based on some encoding scheme.\n",
    "\n",
    "<li> Estimates suggest that Shakespeare's complete works contain around 900,000 to 1,000,000 words. Let's assume a simple encoding scheme where each word is represented by a unique code. For simplicity, we'll assume that each word requires an average of 8 bytes (64 bits) to represent, considering the variability in word length and any additional metadata.\n",
    "\n",
    "Total information content of Shakespeare's works ≈ Number of Words * Size of Encoding per Word\n",
    "\n",
    "= 900,000 words * 64 bits/word\n",
    "\n",
    "= 57,600,000 bits\n",
    "\n",
    "Comparing this with the theoretical capacity of the brain:\n",
    "\n",
    "Total information capacity of the brain = 2 * 10^14 bits\n",
    "\n",
    "Information content of Shakespeare's works = 57,600,000 bits\n",
    "\n",
    "It's evident that the information content of Shakespeare's works (57,600,000 bits) is significantly smaller than the theoretical capacity of the brain (2 * 10^14 bits). Therefore, the information content of Shakespeare's works represents only a tiny fraction of the brain's theoretical capacity, indicating that the brain is far from being \"full\" in terms of its capacity to store information based on this comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chapter 8, Q4 (b) Expand Algorithm 8 to work with more than one binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Equivalent Capacity: 13.92481250360578\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "def calculate_mec(data, labels):\n",
    "    # Determine the number of unique classes\n",
    "    num_classes = len(set(labels))\n",
    "    # Initialize thresholds for each class\n",
    "    thresholds = [0] * num_classes\n",
    "    # Combine data sums and labels into a list of tuples for sorting\n",
    "    data_sums_with_labels = [(sum(datum), label) for datum, label in zip(data, labels)]\n",
    "    # Sort based on data sums\n",
    "    data_sums_with_labels.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Update thresholds based on class transitions\n",
    "    prev_label = data_sums_with_labels[0][1]\n",
    "    for _, label in data_sums_with_labels:\n",
    "        if label != prev_label:\n",
    "            thresholds[label] += 1\n",
    "            prev_label = label\n",
    "    \n",
    "    # Calculate the minimum number of thresholds\n",
    "    total_thresholds = sum(thresholds)\n",
    "    min_thresholds = math.log2(total_thresholds + 1)\n",
    "    # Compute the Minimum Encoding Complexity (MEC)\n",
    "    feature_dimension = len(data[0])\n",
    "    mec = (min_thresholds * (feature_dimension + 1)) + (min_thresholds + 1)\n",
    "    \n",
    "    return mec\n",
    "\n",
    "#Test data\n",
    "data = np.array([[0, 0, 1], [1, 0, 1], [0, 1, 0], [1, 1, 1], [0, 0, 0], [1, 0, 0], [0, 1, 1]])\n",
    "labels = np.array([0, 1, 0, 1, 2, 2, 2])\n",
    "print(\"Memory Equivalent Capacity:\", calculate_mec(data, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chapter 8, Q4(c) Expand Algorithm 8 to work with regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory-equivalent capacity for regression: 10.287712379549449\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import log2\n",
    "\n",
    "def calculate_mec_regression(data, targets, epsilon=0.1):\n",
    "    data = np.array(data)  # Convert data to a NumPy array\n",
    "    targets = np.array(targets)  # Ensure targets is also a NumPy array for consistency\n",
    "    \n",
    "    # Sort targets and data based on the targets\n",
    "    sorted_indices = np.argsort(targets)\n",
    "    sorted_data = data[sorted_indices]\n",
    "    sorted_targets = targets[sorted_indices]\n",
    "\n",
    "    # Initialize segment counting\n",
    "    num_segments = 0\n",
    "    feature_dimension = sorted_data.shape[1]\n",
    "    \n",
    "    # Compare consecutive targets to count the number of segments\n",
    "    last_target = sorted_targets[0]\n",
    "    for target in sorted_targets:\n",
    "        if abs(target - last_target) > epsilon:\n",
    "            num_segments += 1\n",
    "            last_target = target\n",
    "\n",
    "    # Calculate the Minimum Encoding Complexity (MEC) based on the number of segments\n",
    "    total_thresholds = num_segments\n",
    "    min_thresholds = log2(total_thresholds + 1)\n",
    "    mec = (min_thresholds * (feature_dimension + 1)) + (min_thresholds + 1)\n",
    "\n",
    "    return mec\n",
    "\n",
    "data = [\n",
    "    [0.5, 0.3], [1.2, 0.8], [2.0, 1.5],\n",
    "    [2.5, 2.0], [3.0, 2.5], [3.5, 3.0],\n",
    "    [4.0, 3.5], [4.5, 4.0], [5.0, 4.5]\n",
    "]\n",
    "targets = [0.6, 1.0, 1.7, 2.3, 2.8, 3.3, 3.7, 4.2, 4.6]\n",
    "\n",
    "\n",
    "mec = calculate_mec_regression(data, targets, epsilon=0.5)\n",
    "print(\"Memory-equivalent capacity for regression:\", mec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
